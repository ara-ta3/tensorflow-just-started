{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第二章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "import numpy as np\n",
    "\n",
    "class Cifar10Record(object):\n",
    "    width = 32\n",
    "    height = 32\n",
    "    depth = 3\n",
    "    \n",
    "    def set_label(self, label_byte):\n",
    "        self.label = np.frombuffer(label_byte, dtype=np.uint8)\n",
    "    \n",
    "    def set_image(self, image_bytes):\n",
    "        byte_buffer = np.frombuffer(image_bytes, dtype=np.int8)\n",
    "        reshaped_array = np.reshape(byte_buffer, [self.depth, self.height, self.width])\n",
    "        self.byte_array = np.transpose(reshaped_array, [1,2,0])\n",
    "        self.byte_array = self.byte_array.astype(np.float32)\n",
    "        \n",
    "class Cifar10Reader(object):\n",
    "    def __init__(self, filename):\n",
    "        self.bytestream = open(filename, mode=\"rb\")\n",
    "        \n",
    "    def close(self):\n",
    "        if not self.bytestream:\n",
    "            self.bytestream.close()\n",
    "        \n",
    "    def read(self, index):\n",
    "        result = Cifar10Record()\n",
    "        label_bytes = 1\n",
    "        image_bytes = result.height * result.width * result.depth\n",
    "        record_bytes = label_bytes * image_bytes\n",
    "        \n",
    "        self.bytestream.seek(record_bytes * index, 0)\n",
    "        # http://docs.python.jp/3/library/io.html#io.IOBase.seek\n",
    "        result.set_label(self.bytestream.read(label_bytes))\n",
    "        result.set_image(self.bytestream.read(image_bytes))\n",
    "        \n",
    "        return result\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 6\n",
      "label: 72\n",
      "label: 142\n",
      "label: 83\n",
      "label: 38\n",
      "label: 79\n",
      "label: 13\n",
      "label: 58\n",
      "label: 107\n",
      "label: 233\n",
      "label: 60\n",
      "label: 62\n",
      "label: 129\n",
      "label: 98\n",
      "label: 226\n",
      "label: 57\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "# FLAGS = tf.app.flags.FLAGS\n",
    "# tf.app.flags.DEFINE_string('file', './data/data_batch_1.bin', '処理対象ファイルパス')\n",
    "# tf.app.flags.DEFINE_integer('offset', 0, \"読み飛ばすレコード数\")\n",
    "# tf.app.flags.DEFINE_integer('length', 16, \"読み込んで変換するレコード数\")\n",
    "\n",
    "file = \"./data/data_batch_1.bin\"\n",
    "offset = 0\n",
    "length = 16\n",
    "\n",
    "basename = os.path.basename(file)\n",
    "path = os.path.dirname(file)\n",
    "reader = Cifar10Reader(file)\n",
    "\n",
    "stop = offset + length\n",
    "\n",
    "for index in range(offset, stop):\n",
    "    image = reader.read(index)\n",
    "    \n",
    "    print('label: %d' % (image.label))\n",
    "    \n",
    "    imageshow = Image.fromarray(image.byte_array.astype(np.uint8))\n",
    "    \n",
    "    file_name = '%s-%02d-%d.png' % (basename, index, image.label)\n",
    "    \n",
    "    file = os.path.join(path, file_name)\n",
    "    with open(file, mode='wb') as out:\n",
    "        imageshow.save(out, format='png')\n",
    "\n",
    "reader.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "def _get_weights(shape, stddev=1.0):\n",
    "    var = tf.get_variable(\n",
    "    'weights',\n",
    "    shape,\n",
    "    initializer = tf.truncated_normal_initializer(stddev=stddev))\n",
    "    return var\n",
    "\n",
    "def _get_biases(shape, value=0.0):\n",
    "    var = tf.get_variable(\n",
    "    'biases',\n",
    "    shape,\n",
    "    initializer=tf.constant_initializer(value))\n",
    "    return var\n",
    "\n",
    "def inference(image_node):\n",
    "    with tf.variable_scope('conv1') as scope:\n",
    "        weights = _get_weights(shape=[5, 5, 3, 64], stddev=1e-4)\n",
    "        conv = tf.nn.conv2d(image_node, weights, [1,1,1,1], padding='SAME')\n",
    "        biases = _get_biases([64], value=0.1)\n",
    "        bias = tf.nn.bias_add(conv, biases)\n",
    "        conv1 = tf.nn.relu(bias, name=scope.name)\n",
    "    \n",
    "    pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1,2,2,1],\n",
    "                           padding='SAME', name='pool1')\n",
    "    \n",
    "    with tf.variable_scope('conv2') as scope:\n",
    "        weights = _get_weights(shape=[5, 5, 64, 64], stddev=1e-4)\n",
    "        conv = tf.nn.conv2d (pool1, weights, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = _get_biases([64], value=0.1)\n",
    "        bias = tf.nn.bias_add(conv, biases)\n",
    "        conv2 = tf.nn.relu(bias, name=score.name)\n",
    "        \n",
    "    pool2 = tf.nn.max_pool(conv2, ksize=[1,3,3,1], strides=[1,2,2,1],\n",
    "                          padding='SAME', name='pool2')\n",
    "    reshape =tf.reshape(pool2, [1, -1])\n",
    "    dim = reshape.get_shape()[1].value\n",
    "    \n",
    "    with tf.variable_scope('fc3') as scope:\n",
    "        weights = _get_weights(shape=[dim, 384], stddev=0.04)\n",
    "        biases = _get_biases([384], value=0.1)\n",
    "        fc3 = tf.nn.relu(\n",
    "        tf.matmul(reshape, weights) + biases,\n",
    "        name=score.name)\n",
    "    \n",
    "    with tf.variable_scope('fc4') as scope:\n",
    "        weights = _get_weights(shape=[384, 192], stddev=0.04)\n",
    "        biases = _get_biases([192], value=0.1)\n",
    "        fc4 = tf.nn.relu(tf.matmul(fc3, weights) + biases, name=score.name)\n",
    "        \n",
    "    with tf.variable_scope('output') as scope:\n",
    "        weights = _get_weights(shape=[192, NUM_CLASSES], stddev=1 / 192.0)\n",
    "        biases = _get_biases([NUM_CLASSES], value=0.0)\n",
    "        logits = tf.add(tf.matmul(fc4, weights), biases, name='logits')\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
